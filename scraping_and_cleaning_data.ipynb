{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING & SCRAPING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import re\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def init_driver(headless=True, timeout=20):\n",
    "    \"\"\"Create and return a single Chrome WebDriver with safe options.\"\"\"\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options, service=Service(ChromeDriverManager().install()))\n",
    "    try:\n",
    "        driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => false});\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    driver.set_page_load_timeout(timeout)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coords_from_url(url):\n",
    "    \"\"\"Extract latitude and longitude from common Google Maps URL patterns.\"\"\"\n",
    "    try:\n",
    "        m = re.search(r\"@(-?\\d+\\.\\d+),(-?\\d+\\.\\d+)\", url)\n",
    "        if m:\n",
    "            return m.group(1), m.group(2)\n",
    "        m = re.search(r\"3d(-?\\d+\\.\\d+)!4d(-?\\d+\\.\\d+)\", url)\n",
    "        if m:\n",
    "            return m.group(1), m.group(2)\n",
    "        m = re.search(r\"/@(-?\\d+\\.\\d+),(-?\\d+\\.\\d+)\", url)\n",
    "        if m:\n",
    "            return m.group(1), m.group(2)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wait_for_coords_in_url(driver, max_wait=10):\n",
    "    \"\"\"Wait for coordinates to appear in the URL (up to max_wait seconds).\"\"\"\n",
    "    start = time.time()\n",
    "    while time.time() - start < max_wait:\n",
    "        url = driver.current_url\n",
    "        lat, lon = extract_coords_from_url(url)\n",
    "        if lat and lon:\n",
    "            return lat, lon\n",
    "        time.sleep(0.5)\n",
    "    return extract_coords_from_url(driver.current_url)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coords_from_page(driver):\n",
    "    \"\"\"Fallback: Try to extract coordinates from the info panel or share link on the page.\"\"\"\n",
    "    try:\n",
    "        share_button = driver.find_element(By.XPATH, \"//*[contains(@aria-label, 'Share') or contains(@aria-label, 'Bagikan')]\")\n",
    "        driver.execute_script(\"arguments[0].click();\", share_button)\n",
    "        time.sleep(0.8)\n",
    "        try:\n",
    "            share_link = driver.find_element(By.XPATH, \"//input[@value]\")\n",
    "            url = share_link.get_attribute(\"value\")\n",
    "            lat, lon = extract_coords_from_url(url)\n",
    "            if lat and lon:\n",
    "                return lat, lon\n",
    "        except Exception:\n",
    "            pass\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mendapatkan informasi dari Google Maps berdasarkan nama tempat\n",
    "def get_place_status(driver):\n",
    "    \"\"\"Infer place status (Aktif/Tutup Permanen/Tutup Sementara) from page content.\"\"\"\n",
    "    try:\n",
    "        html = driver.page_source.lower()\n",
    "        if ('permanently closed' in html) or ('tutup permanen' in html):\n",
    "            return 'Tutup Permanen'\n",
    "        if ('temporarily closed' in html) or ('tutup sementara' in html):\n",
    "            return 'Tutup Sementara'\n",
    "        if any(w in html for w in ['open now', 'opens', 'closes', 'hours', 'jam', 'buka']):\n",
    "            return 'Aktif'\n",
    "        if ('closed' in html) or ('ditutup' in html):\n",
    "            return 'Tutup'\n",
    "        if ('open' in html) or ('buka' in html):\n",
    "            return 'Aktif'\n",
    "    except Exception:\n",
    "        pass\n",
    "    return 'Aktif'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mendapatkan informasi dari Google Maps berdasarkan nama tempat\n",
    "def get_place_info(driver, place_name, max_result=5, timeout=20):\n",
    "    \"\"\"Use an existing driver to search and scrape up to max_result items sequentially.\"\"\"\n",
    "    wait = WebDriverWait(driver, timeout)\n",
    "    results_data = []\n",
    "    search_url = f\"https://www.google.com/maps/search/{quote(place_name)}\"\n",
    "    try:\n",
    "        driver.get(search_url)\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Gagal membuka URL untuk '{place_name}': {e}\")\n",
    "        return [{\"Place\": place_name, \"Actual Place Name\": \"Error: Gagal membuka URL\", \"Address\": \"Gagal\", \"Phone Number\": \"Gagal\", \"Website\": \"Gagal\", \"Latitude\": \"Gagal\", \"Longitude\": \"Gagal\", \"Status\": \"Error\"}]\n",
    "\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Scroll panel hasil untuk memuat semua cards\n",
    "    try:\n",
    "        results_panel = driver.find_element(By.CSS_SELECTOR, \"div[role='main']\")\n",
    "        for _ in range(3):  # Scroll 3x untuk memuat lebih banyak results\n",
    "            driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", results_panel)\n",
    "            time.sleep(0.5)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Coba scrape langsung dari card list (tanpa klik)\n",
    "    # Selector yang lebih spesifik - hanya ambil card yang punya link\n",
    "    card_link_selectors = [\n",
    "        \"a.hfpxzc\"\n",
    "    ]\n",
    "    \n",
    "    card_links = []\n",
    "    for sel in card_link_selectors:\n",
    "        try:\n",
    "            card_links = driver.find_elements(By.CSS_SELECTOR, sel)\n",
    "            if card_links:\n",
    "                logging.info(f\"Ditemukan {len(card_links)} valid place cards\")\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    # Scrape langsung dari list cards berdasarkan link (lebih akurat)\n",
    "    if card_links and len(card_links) > 0:\n",
    "        logging.info(f\"Scraping langsung dari {min(max_result, len(card_links))} cards...\")\n",
    "        for i, link in enumerate(card_links[:max_result]):\n",
    "            try:\n",
    "                # Cari parent container yang tepat - div.Nv2PK.fontBodyMedium adalah container data\n",
    "                # Gunakan ancestor::*[1] untuk mendapat parent terdekat yang match\n",
    "                try:\n",
    "                    card = link.find_element(By.XPATH, \"./ancestor::div[contains(@class, 'Nv2PK')][1]\")\n",
    "                except:\n",
    "                    # Fallback jika tidak ketemu\n",
    "                    card = link.find_element(By.XPATH, \"./ancestor::div[contains(@class, 'm6QErb')][1]\")\n",
    "                \n",
    "                # Debugging: print class dari card untuk memastikan\n",
    "                card_class = card.get_attribute(\"class\")\n",
    "                logging.debug(f\"Card {i+1} class: {card_class}\")\n",
    "                \n",
    "                data = {\n",
    "                    \"Place\": place_name,\n",
    "                    \"Actual Place Name\": \"Gagal\",\n",
    "                    \"Category\": \"Gagal\",\n",
    "                    \"Rating\": \"Gagal\",\n",
    "                    \"Address\": \"Gagal\",\n",
    "                    \"Phone Number\": \"Gagal\",\n",
    "                    \"Website\": \"Gagal\",\n",
    "                    \"Latitude\": \"Gagal\",\n",
    "                    \"Longitude\": \"Gagal\",\n",
    "                    \"Status\": \"Aktif\",\n",
    "                    \"Operation Hours\": \"Gagal\",\n",
    "                    \"Open Status\": \"Gagal\"\n",
    "                }\n",
    "                \n",
    "                # === 1. NAMA TEMPAT - dari aria-label atau div.qBF1Pd ===\n",
    "                name_found = False\n",
    "                try:\n",
    "                    aria_label = link.get_attribute(\"aria-label\")\n",
    "                    if aria_label and len(aria_label) > 0:\n",
    "                        name = aria_label.split(\"¬∑\")[0].strip()\n",
    "                        invalid_names = ['foto & video', 'foto', 'video', 'photos', 'reviews', 'menu', 'about', '']\n",
    "                        if name.lower() not in invalid_names and len(name) > 2:\n",
    "                            data[\"Actual Place Name\"] = name\n",
    "                            logging.info(f\"Card {i+1}: ‚úì Nama: {name[:50]}\")\n",
    "                            name_found = True\n",
    "                except Exception as e:\n",
    "                    logging.debug(f\"Card {i+1}: Gagal dari aria-label: {str(e)[:30]}\")\n",
    "                \n",
    "                if not name_found:\n",
    "                    try:\n",
    "                        elem = card.find_element(By.CSS_SELECTOR, \".qBF1Pd.fontHeadlineSmall\")\n",
    "                        name = elem.text.strip()\n",
    "                        invalid_names = ['foto & video', 'foto', 'video', 'photos', 'reviews', 'menu', 'about', '']\n",
    "                        if name and len(name) > 2 and name.lower() not in invalid_names:\n",
    "                            data[\"Actual Place Name\"] = name\n",
    "                            logging.info(f\"Card {i+1}: ‚úì Nama (fallback): {name[:50]}\")\n",
    "                            name_found = True\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                \n",
    "                if not name_found:\n",
    "                    logging.warning(f\"Card {i+1}: Gagal ambil nama, skip\")\n",
    "                    continue\n",
    "                \n",
    "                # === 2. CATEGORY - dari span, cari yang bukan rating/address/phone ===\n",
    "                try:\n",
    "                    # Cari semua span dalam card, filter yang merupakan category\n",
    "                    all_category_spans = card.find_elements(By.XPATH, \".//span\")\n",
    "                    for elem in all_category_spans:\n",
    "                        category_text = elem.text.strip()\n",
    "                        if not category_text or len(category_text) < 3:\n",
    "                            continue\n",
    "                        # Skip jika ada angka (kemungkinan rating atau phone)\n",
    "                        if any(c.isdigit() for c in category_text):\n",
    "                            continue\n",
    "                        # Skip jika ada keyword alamat\n",
    "                        if any(kw in category_text.lower() for kw in ['jl', 'jalan', 'street', 'no.', 'blok', 'rt.', 'rw.']):\n",
    "                            continue\n",
    "                        # Skip jika terlalu panjang\n",
    "                        if len(category_text) > 50:\n",
    "                            continue\n",
    "                        # Skip jika mengandung simbol phone/address\n",
    "                        if any(char in category_text for char in ['+', '(', ')', '-', '/'] if category_text.count(char) > 1):\n",
    "                            continue\n",
    "                        # Ini kemungkinan category\n",
    "                        data[\"Category\"] = category_text\n",
    "                        logging.info(f\"Card {i+1}: ‚úì Category: {category_text}\")\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    logging.debug(f\"Card {i+1}: Category error: {str(e)[:50]}\")\n",
    "                    pass\n",
    "                \n",
    "                # === 3. RATING - dari span dengan aria-label atau MW4etd (dalam card ini) ===\n",
    "                try:\n",
    "                    rating_elem = card.find_element(By.XPATH, \".//span[contains(@class, 'MW4etd')]\")\n",
    "                    rating_text = rating_elem.text.strip()\n",
    "                    if rating_text and len(rating_text) > 0:\n",
    "                        data[\"Rating\"] = rating_text\n",
    "                        logging.info(f\"Card {i+1}: ‚úì Rating: {rating_text}\")\n",
    "                except Exception:\n",
    "                    # Alternatif: cari dari aria-label yang mengandung rating\n",
    "                    try:\n",
    "                        rating_elem = card.find_element(By.XPATH, \".//span[contains(@aria-label, 'star') or contains(@aria-label, 'stars')]\")\n",
    "                        aria_rating = rating_elem.get_attribute(\"aria-label\")\n",
    "                        if aria_rating:\n",
    "                            # Extract number dari \"4.5 stars\" atau similar\n",
    "                            import re\n",
    "                            match = re.search(r'(\\d+\\.?\\d*)', aria_rating)\n",
    "                            if match:\n",
    "                                data[\"Rating\"] = match.group(1)\n",
    "                                logging.info(f\"Card {i+1}: ‚úì Rating (aria): {match.group(1)}\")\n",
    "                    except Exception:\n",
    "                        # Jika tidak ada rating, set \"No reviews\"\n",
    "                        try:\n",
    "                            no_review = card.find_element(By.XPATH, \".//span[contains(text(), 'No reviews') or contains(text(), 'review')]\")\n",
    "                            if no_review:\n",
    "                                data[\"Rating\"] = \"No reviews\"\n",
    "                                logging.info(f\"Card {i+1}: ‚úì Rating: No reviews\")\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                \n",
    "                # === 4 & 5. ALAMAT dan PHONE - dari semua span dalam card ===\n",
    "                try:\n",
    "                    # PENTING: Gunakan .// untuk mencari hanya dalam card ini\n",
    "                    all_spans = card.find_elements(By.XPATH, \".//span\")\n",
    "                    \n",
    "                    # Kumpulkan semua teks untuk debugging\n",
    "                    span_texts = [s.text.strip() for s in all_spans if s.text.strip()]\n",
    "                    logging.debug(f\"Card {i+1}: Found {len(span_texts)} spans with text\")\n",
    "                    \n",
    "                    for elem in all_spans:\n",
    "                        text = elem.text.strip()\n",
    "                        if not text or len(text) < 8:\n",
    "                            continue\n",
    "                        \n",
    "                        # Skip jika sudah dapat keduanya\n",
    "                        if data[\"Address\"] != \"Gagal\" and data[\"Phone Number\"] != \"Gagal\":\n",
    "                            break\n",
    "                        \n",
    "                        # Cek apakah ini alamat (prioritas lebih tinggi)\n",
    "                        if data[\"Address\"] == \"Gagal\":\n",
    "                            address_keywords = ['jl.', 'jl ', 'jalan', 'street', 'no.', 'no ', 'blok', 'rt.', 'rw.', 'kec.', 'kel.']\n",
    "                            if any(kw in text.lower() for kw in address_keywords):\n",
    "                                # Pastikan bukan pure number\n",
    "                                if not text.replace('-', '').replace('.', '').replace(' ', '').replace('/', '').isdigit():\n",
    "                                    # Pastikan tidak dimulai dengan karakter phone\n",
    "                                    if len(text) > 0 and text[0] not in ['+', '0', '(']:\n",
    "                                        data[\"Address\"] = text\n",
    "                                        logging.info(f\"Card {i+1}: ‚úì Alamat: {text[:50]}\")\n",
    "                                        continue\n",
    "                        \n",
    "                        # Cek apakah ini phone number\n",
    "                        if data[\"Phone Number\"] == \"Gagal\":\n",
    "                            # Phone harus dimulai dengan karakter phone\n",
    "                            if len(text) > 0 and text[0] in ['+', '0', '(', '6', '8']:\n",
    "                                # Hitung jumlah digit\n",
    "                                digit_count = sum(c.isdigit() for c in text)\n",
    "                                if digit_count >= 6:\n",
    "                                    # Tidak boleh ada keyword alamat\n",
    "                                    invalid_keywords = ['jl.', 'jl ', 'jalan', 'street', 'blok', 'rt.', 'rw.', 'kec.', 'kel.']\n",
    "                                    if not any(kw in text.lower() for kw in invalid_keywords):\n",
    "                                        data[\"Phone Number\"] = text\n",
    "                                        logging.info(f\"Card {i+1}: ‚úì Phone: {text}\")\n",
    "                                        continue\n",
    "                except Exception as e:\n",
    "                    logging.debug(f\"Card {i+1}: Address/Phone error: {str(e)[:50]}\")\n",
    "                    pass\n",
    "                \n",
    "                # === 6. OPERATION HOURS & STATUS - dari span dalam card ===\n",
    "                try:\n",
    "                    # Cari semua span yang mengandung info jam\n",
    "                    hours_spans = card.find_elements(By.XPATH, \".//span\")\n",
    "                    \n",
    "                    full_hours_text = []\n",
    "                    for elem in hours_spans:\n",
    "                        text = elem.text.strip()\n",
    "                        if text and any(kw in text.lower() for kw in ['open', 'close', 'buka', 'tutup', 'am', 'pm', 'wib']):\n",
    "                            full_hours_text.append(text)\n",
    "                            \n",
    "                            # Tentukan status berdasarkan keyword\n",
    "                            if any(kw in text.lower() for kw in ['permanently closed', 'tutup permanen', 'closed permanently']):\n",
    "                                data[\"Status\"] = \"Tutup Permanen\"\n",
    "                                data[\"Open Status\"] = text\n",
    "                            elif any(kw in text.lower() for kw in ['temporarily closed', 'tutup sementara', 'closed temporarily']):\n",
    "                                data[\"Status\"] = \"Tutup Sementara\"\n",
    "                                data[\"Open Status\"] = text\n",
    "                            elif 'closed' in text.lower() or 'tutup' in text.lower():\n",
    "                                if 'open' not in text.lower():\n",
    "                                    data[\"Status\"] = \"Tutup\"\n",
    "                                    data[\"Open Status\"] = text\n",
    "                            elif 'open' in text.lower() or 'buka' in text.lower():\n",
    "                                data[\"Status\"] = \"Aktif\"\n",
    "                                if not data[\"Open Status\"] or data[\"Open Status\"] == \"Gagal\":\n",
    "                                    data[\"Open Status\"] = text\n",
    "                    \n",
    "                    # Gabungkan semua teks jam jika ada\n",
    "                    if full_hours_text:\n",
    "                        # Filter yang benar-benar jam (ada angka)\n",
    "                        hours_with_time = [h for h in full_hours_text if any(c.isdigit() for c in h)]\n",
    "                        if hours_with_time:\n",
    "                            data[\"Operation Hours\"] = \" ¬∑ \".join(hours_with_time[:2])  # Ambil max 2 elemen\n",
    "                            logging.info(f\"Card {i+1}: ‚úì Hours: {data['Operation Hours']}\")\n",
    "                        if data[\"Open Status\"] != \"Gagal\":\n",
    "                            logging.info(f\"Card {i+1}: ‚úì Open Status: {data['Open Status']}\")\n",
    "                except Exception as e:\n",
    "                    logging.debug(f\"Card {i+1}: Hours/Status error: {str(e)[:50]}\")\n",
    "                    pass\n",
    "                \n",
    "                # === 7. WEBSITE - coba dari aria-label atau attribute ===\n",
    "                # Google Maps cards biasanya tidak menampilkan website di list, hanya di detail\n",
    "                # Tapi kita tetap coba\n",
    "                try:\n",
    "                    website_elem = card.find_element(By.CSS_SELECTOR, \"a[data-value='website']\")\n",
    "                    website_url = website_elem.get_attribute(\"href\")\n",
    "                    if website_url:\n",
    "                        data[\"Website\"] = website_url\n",
    "                        logging.info(f\"Card {i+1}: ‚úì Website: {website_url[:50]}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "                \n",
    "                # === 8. KOORDINAT - dari href link ===\n",
    "                # Get URL untuk extract koordinat dari link yang sudah ada\n",
    "                try:\n",
    "                    url = link.get_attribute(\"href\")\n",
    "                    if url:\n",
    "                        lat, lon = extract_coords_from_url(url)\n",
    "                        if lat and lon:\n",
    "                            data[\"Latitude\"], data[\"Longitude\"] = lat, lon\n",
    "                            logging.info(f\"Card {i+1}: ‚úì Koordinat: {lat}, {lon}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "                \n",
    "                results_data.append(data)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Card {i+1}: Error - {str(e)[:100]}\")\n",
    "                continue\n",
    "        \n",
    "        if results_data:\n",
    "            logging.info(f\"‚úì Berhasil scrape {len(results_data)} cards dari list\")\n",
    "            return results_data\n",
    "    \n",
    "    # Fallback: coba metode lama (klik satu-satu)\n",
    "    logging.info(\"Fallback ke metode klik card satu-satu...\")\n",
    "    cards_selector_candidates = [\".hfpxzc\", \".Nv2PK\"]\n",
    "    cards = []\n",
    "    for sel in cards_selector_candidates:\n",
    "        try:\n",
    "            cards = driver.find_elements(By.CSS_SELECTOR, sel)\n",
    "            if cards:\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # Jika tidak ada kartu, mungkin langsung ke halaman tempat atau tidak ditemukan\n",
    "    if not cards:\n",
    "        # Wait for place details panel to load\n",
    "        try:\n",
    "            WebDriverWait(driver, 8).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"h1.DUwDvf\"))\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Tidak ada hasil atau halaman tidak muncul\n",
    "            logging.warning(f\"Tidak ditemukan hasil untuk '{place_name}': {str(e)[:100]}\")\n",
    "            return [{\"Place\": place_name, \"Actual Place Name\": \"Tidak ditemukan - No results\", \"Address\": \"Gagal\", \"Phone Number\": \"Gagal\", \"Website\": \"Gagal\", \"Latitude\": \"Gagal\", \"Longitude\": \"Gagal\", \"Status\": \"Error\"}]\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        data = {\n",
    "            \"Place\": place_name,\n",
    "            \"Actual Place Name\": \"Gagal\",\n",
    "            \"Category\": \"Gagal\",\n",
    "            \"Rating\": \"Gagal\",\n",
    "            \"Address\": \"Gagal\",\n",
    "            \"Phone Number\": \"Gagal\",\n",
    "            \"Website\": \"Gagal\",\n",
    "            \"Latitude\": \"Gagal\",\n",
    "            \"Longitude\": \"Gagal\",\n",
    "            \"Status\": get_place_status(driver),\n",
    "            \"Operation Hours\": \"Gagal\",\n",
    "            \"Open Status\": \"Gagal\"\n",
    "        }\n",
    "        try:\n",
    "            actual_name = driver.find_element(By.CSS_SELECTOR, \"h1.DUwDvf\").text\n",
    "            if actual_name and len(actual_name.strip()) > 0:\n",
    "                data[\"Actual Place Name\"] = actual_name\n",
    "            else:\n",
    "                logging.warning(f\"Place name kosong untuk '{place_name}'\")\n",
    "                return [{\"Place\": place_name, \"Actual Place Name\": \"Error: Nama tempat kosong\", \"Address\": \"Gagal\", \"Phone Number\": \"Gagal\", \"Website\": \"Gagal\", \"Latitude\": \"Gagal\", \"Longitude\": \"Gagal\", \"Status\": \"Error\"}]\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Gagal mendapatkan place name untuk '{place_name}': {str(e)[:100]}\")\n",
    "            return [{\"Place\": place_name, \"Actual Place Name\": f\"Error: {str(e)[:50]}\", \"Address\": \"Gagal\", \"Phone Number\": \"Gagal\", \"Website\": \"Gagal\", \"Latitude\": \"Gagal\", \"Longitude\": \"Gagal\", \"Status\": \"Error\"}]\n",
    "        try:\n",
    "            data[\"Address\"] = driver.find_element(By.CSS_SELECTOR, '[data-item-id=\"address\"]').text\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            phone_el = driver.find_element(By.CSS_SELECTOR, '[data-item-id=\"phone\"]')\n",
    "            data[\"Phone Number\"] = phone_el.text\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            we = driver.find_element(By.CSS_SELECTOR, '[data-item-id=\"authority\"]')\n",
    "            data[\"Website\"] = we.get_attribute(\"href\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        # Rating dari detail page\n",
    "        try:\n",
    "            rating_elem = driver.find_element(By.CSS_SELECTOR, \"div.F7nice > span > span[aria-hidden='true']\")\n",
    "            rating_text = rating_elem.text.strip()\n",
    "            if rating_text:\n",
    "                data[\"Rating\"] = rating_text\n",
    "        except Exception:\n",
    "            try:\n",
    "                rating_elem = driver.find_element(By.CSS_SELECTOR, \"span.ceNzKf[aria-label*='star' i]\")\n",
    "                aria_rating = rating_elem.get_attribute(\"aria-label\")\n",
    "                if aria_rating:\n",
    "                    match = re.search(r'(\\d+\\.?\\d*)', aria_rating)\n",
    "                    if match:\n",
    "                        data[\"Rating\"] = match.group(1)\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        # Try multiple selectors untuk Category\n",
    "        category_selectors = [\n",
    "            (By.CSS_SELECTOR, \"button.DkEaL\"),\n",
    "            (By.XPATH, \"//button[contains(@class, 'DkEaL')]\"),\n",
    "            (By.CSS_SELECTOR, \"button[jsaction*='category']\"),\n",
    "            (By.XPATH, \"//div[@class='fontBodyMedium dmRWX']//button\")\n",
    "        ]\n",
    "        \n",
    "        for by, selector in category_selectors:\n",
    "            try:\n",
    "                elem = driver.find_element(by, selector)\n",
    "                type_text = elem.text\n",
    "                if type_text and len(type_text.strip()) > 0:\n",
    "                    data[\"Category\"] = type_text.strip()\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        # Try multiple selectors untuk Open Status\n",
    "        status_selectors = [\n",
    "            (By.XPATH, \"//span[contains(@class, 'ZDu9vd')]//span[2]\"),\n",
    "            (By.CSS_SELECTOR, \"span.ZDu9vd span:nth-child(2)\"),\n",
    "            (By.XPATH, \"//div[contains(@aria-label, 'Hours')]//span[contains(text(), 'Open') or contains(text(), 'Closed') or contains(text(), 'Buka') or contains(text(), 'Tutup')]\"),\n",
    "            (By.XPATH, \"//div[contains(text(), 'Opens') or contains(text(), 'Closes') or contains(text(), 'Buka') or contains(text(), 'Tutup')]\")\n",
    "        ]\n",
    "        \n",
    "        for by, selector in status_selectors:\n",
    "            try:\n",
    "                elem = driver.find_element(by, selector)\n",
    "                status_text = elem.text\n",
    "                if status_text and len(status_text.strip()) > 0:\n",
    "                    data[\"Open Status\"] = status_text.strip()\n",
    "                    \n",
    "                    # Update status based on open status text\n",
    "                    if any(kw in status_text.lower() for kw in ['permanently closed', 'tutup permanen']):\n",
    "                        data[\"Status\"] = \"Tutup Permanen\"\n",
    "                    elif any(kw in status_text.lower() for kw in ['temporarily closed', 'tutup sementara']):\n",
    "                        data[\"Status\"] = \"Tutup Sementara\"\n",
    "                    elif 'closed' in status_text.lower() or 'tutup' in status_text.lower():\n",
    "                        data[\"Status\"] = \"Tutup\"\n",
    "                    else:\n",
    "                        data[\"Status\"] = \"Aktif\"\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        # Extract Operation Hours dari tombol/div hours\n",
    "        try:\n",
    "            hours_button = driver.find_element(By.CSS_SELECTOR, \"button[data-item-id='oh']\")\n",
    "            hours_aria = hours_button.get_attribute(\"aria-label\")\n",
    "            if hours_aria:\n",
    "                data[\"Operation Hours\"] = hours_aria\n",
    "        except Exception:\n",
    "            try:\n",
    "                # Alternatif: cari dari div yang menampilkan jam\n",
    "                hours_div = driver.find_element(By.XPATH, \"//div[contains(@class, 'ZDu9vd')]//span\")\n",
    "                hours_text = hours_div.text.strip()\n",
    "                if hours_text and re.search(r'\\d{1,2}[:.\\-]\\d{2}', hours_text):\n",
    "                    data[\"Operation Hours\"] = hours_text\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        lat, lon = wait_for_coords_in_url(driver, max_wait=10)\n",
    "        if not lat or not lon:\n",
    "            lat, lon = extract_coords_from_page(driver)\n",
    "        if lat and lon:\n",
    "            data[\"Latitude\"], data[\"Longitude\"] = lat, lon\n",
    "        data[\"Status\"] = get_place_status(driver)\n",
    "        results_data.append(data)\n",
    "        return results_data\n",
    "\n",
    "    # Jika ada list hasil, klik satu per satu\n",
    "    for i in range(min(max_result, len(cards))):\n",
    "        try:\n",
    "            cards = cards if i < len(cards) else driver.find_elements(By.CSS_SELECTOR, cards_selector_candidates[0])\n",
    "            if i >= len(cards):\n",
    "                break\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", cards[i])\n",
    "            time.sleep(0.8)\n",
    "            old_url = driver.current_url\n",
    "            driver.execute_script(\"arguments[0].click();\", cards[i])\n",
    "            \n",
    "            # Wait for place details panel to load dengan multiple attempts\n",
    "            detail_loaded = False\n",
    "            for attempt in range(3):\n",
    "                try:\n",
    "                    WebDriverWait(driver, 5).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, \"h1.DUwDvf\"))\n",
    "                    )\n",
    "                    detail_loaded = True\n",
    "                    logging.info(f\"Card {i+1}: Detail panel loaded\")\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Card {i+1}: Attempt {attempt+1} - Detail panel not loaded: {str(e)[:50]}\")\n",
    "                    time.sleep(1)\n",
    "            \n",
    "            if not detail_loaded:\n",
    "                logging.error(f\"Card {i+1}: Detail panel gagal load setelah 3 attempts\")\n",
    "                continue\n",
    "            \n",
    "            # Extra wait untuk memastikan semua element loaded\n",
    "            time.sleep(1.5)\n",
    "            \n",
    "            # Wait for URL to update with coordinates\n",
    "            lat, lon = wait_for_coords_in_url(driver, max_wait=12)\n",
    "\n",
    "            data = {\n",
    "                \"Place\": place_name,\n",
    "                \"Actual Place Name\": \"Gagal\",\n",
    "                \"Category\": \"Gagal\",\n",
    "                \"Rating\": \"Gagal\",\n",
    "                \"Address\": \"Gagal\",\n",
    "                \"Phone Number\": \"Gagal\",\n",
    "                \"Website\": \"Gagal\",\n",
    "                \"Latitude\": \"Gagal\",\n",
    "                \"Longitude\": \"Gagal\",\n",
    "                \"Status\": \"Aktif\",\n",
    "                \"Operation Hours\": \"Gagal\",\n",
    "                \"Open Status\": \"Gagal\"\n",
    "            }\n",
    "            # Try multiple selectors untuk actual place name\n",
    "            actual_name = None\n",
    "            name_selectors = [\n",
    "                (By.CSS_SELECTOR, \"h1.DUwDvf\"),\n",
    "                (By.CSS_SELECTOR, \"h1.fontHeadlineLarge\"),\n",
    "                (By.XPATH, \"//h1[@class='DUwDvf lfPIob']\"),\n",
    "                (By.XPATH, \"/html/body/div[1]/div[2]/div[9]/div[8]/div/div/div[1]/div[2]/div/div[1]/div/div/div[1]/div[1]/div[1]/div/div[2]/div[4]/div[1]/div/div/div[2]/div[1]/div[2]\"),\n",
    "                (By.XPATH, \"//div[@class='fontHeadlineLarge']//span\"),\n",
    "                (By.CSS_SELECTOR, \"div.fontHeadlineLarge span\")\n",
    "            ]\n",
    "            \n",
    "            for by, selector in name_selectors:\n",
    "                try:\n",
    "                    # Wait untuk element muncul dulu\n",
    "                    WebDriverWait(driver, 3).until(\n",
    "                        EC.presence_of_element_located((by, selector))\n",
    "                    )\n",
    "                    elem = driver.find_element(by, selector)\n",
    "                    actual_name = elem.text\n",
    "                    if actual_name and len(actual_name.strip()) > 0:\n",
    "                        data[\"Actual Place Name\"] = actual_name.strip()\n",
    "                        logging.info(f\"Card {i+1}: ‚úì Nama: {actual_name.strip()[:50]} (via {by})\")\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    logging.debug(f\"Card {i+1}: Selector {by} gagal: {str(e)[:30]}\")\n",
    "                    continue\n",
    "            \n",
    "            if not actual_name or len(actual_name.strip()) == 0:\n",
    "                logging.error(f\"Card {i+1}: ‚úó Semua selector nama gagal untuk '{place_name}'\")\n",
    "                data[\"Actual Place Name\"] = f\"Error: Gagal ambil nama (card {i+1})\"\n",
    "                continue\n",
    "            # Try multiple selectors untuk address\n",
    "            address_selectors = [\n",
    "                (By.CSS_SELECTOR, '[data-item-id=\"address\"]'),\n",
    "                (By.XPATH, \"//button[@data-item-id='address']//div[contains(@class, 'fontBodyMedium')]\"),\n",
    "                (By.CSS_SELECTOR, \"button[data-item-id='address'] div.fontBodyMedium\"),\n",
    "                (By.XPATH, \"//div[@class='Io6YTe fontBodyMedium kR99db fdkmkc']\")\n",
    "            ]\n",
    "            \n",
    "            for by, selector in address_selectors:\n",
    "                try:\n",
    "                    elem = driver.find_element(by, selector)\n",
    "                    address_text = elem.text\n",
    "                    if address_text and len(address_text.strip()) > 0:\n",
    "                        data[\"Address\"] = address_text.strip()\n",
    "                        logging.info(f\"Card {i+1}: ‚úì Alamat ditemukan\")\n",
    "                        break\n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            # Phone Number\n",
    "            try:\n",
    "                phone_el = driver.find_element(By.CSS_SELECTOR, '[data-item-id=\"phone\"]')\n",
    "                phone_text = phone_el.text\n",
    "                if phone_text and len(phone_text.strip()) > 0:\n",
    "                    data[\"Phone Number\"] = phone_text.strip()\n",
    "                    logging.info(f\"Card {i+1}: ‚úì Phone ditemukan\")\n",
    "            except Exception:\n",
    "                logging.debug(f\"Card {i+1}: Phone tidak ditemukan\")\n",
    "                pass\n",
    "            \n",
    "            # Website\n",
    "            try:\n",
    "                we = driver.find_element(By.CSS_SELECTOR, '[data-item-id=\"authority\"]')\n",
    "                website_url = we.get_attribute(\"href\")\n",
    "                if website_url:\n",
    "                    data[\"Website\"] = website_url\n",
    "                    logging.info(f\"Card {i+1}: ‚úì Website ditemukan\")\n",
    "            except Exception:\n",
    "                logging.debug(f\"Card {i+1}: Website tidak ditemukan\")\n",
    "                pass\n",
    "            \n",
    "            # Rating dari detail page\n",
    "            try:\n",
    "                rating_elem = driver.find_element(By.CSS_SELECTOR, \"div.F7nice > span > span[aria-hidden='true']\")\n",
    "                rating_text = rating_elem.text.strip()\n",
    "                if rating_text:\n",
    "                    data[\"Rating\"] = rating_text\n",
    "                    logging.info(f\"Card {i+1}: ‚úì Rating: {rating_text}\")\n",
    "            except Exception:\n",
    "                try:\n",
    "                    rating_elem = driver.find_element(By.CSS_SELECTOR, \"span.ceNzKf[aria-label*='star' i]\")\n",
    "                    aria_rating = rating_elem.get_attribute(\"aria-label\")\n",
    "                    if aria_rating:\n",
    "                        match = re.search(r'(\\d+\\.?\\d*)', aria_rating)\n",
    "                        if match:\n",
    "                            data[\"Rating\"] = match.group(1)\n",
    "                            logging.info(f\"Card {i+1}: ‚úì Rating: {match.group(1)}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "            \n",
    "            # Try multiple selectors untuk Category\n",
    "            category_selectors = [\n",
    "                (By.CSS_SELECTOR, \"button.DkEaL\"),\n",
    "                (By.XPATH, \"//button[contains(@class, 'DkEaL')]\"),\n",
    "                (By.CSS_SELECTOR, \"button[jsaction*='category']\"),\n",
    "                (By.XPATH, \"//div[@class='fontBodyMedium dmRWX']//button\")\n",
    "            ]\n",
    "            \n",
    "            for by, selector in category_selectors:\n",
    "                try:\n",
    "                    elem = driver.find_element(by, selector)\n",
    "                    category_text = elem.text\n",
    "                    if category_text and len(category_text.strip()) > 0:\n",
    "                        data[\"Category\"] = category_text.strip()\n",
    "                        logging.info(f\"Card {i+1}: ‚úì Category: {category_text.strip()}\")\n",
    "                        break\n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            # Try multiple selectors untuk Open Status\n",
    "            status_selectors = [\n",
    "                (By.XPATH, \"//span[contains(@class, 'ZDu9vd')]//span[2]\"),\n",
    "                (By.CSS_SELECTOR, \"span.ZDu9vd span:nth-child(2)\"),\n",
    "                (By.XPATH, \"//div[contains(@aria-label, 'Hours')]//span[contains(text(), 'Open') or contains(text(), 'Closed') or contains(text(), 'Buka') or contains(text(), 'Tutup')]\"),\n",
    "                (By.XPATH, \"//div[contains(text(), 'Opens') or contains(text(), 'Closes') or contains(text(), 'Buka') or contains(text(), 'Tutup')]\")\n",
    "            ]\n",
    "            \n",
    "            for by, selector in status_selectors:\n",
    "                try:\n",
    "                    elem = driver.find_element(by, selector)\n",
    "                    status_text = elem.text\n",
    "                    if status_text and len(status_text.strip()) > 0:\n",
    "                        data[\"Open Status\"] = status_text.strip()\n",
    "                        logging.info(f\"Card {i+1}: ‚úì Open Status: {status_text.strip()}\")\n",
    "                        \n",
    "                        # Update status based on text\n",
    "                        if any(kw in status_text.lower() for kw in ['permanently closed', 'tutup permanen']):\n",
    "                            data[\"Status\"] = \"Tutup Permanen\"\n",
    "                        elif any(kw in status_text.lower() for kw in ['temporarily closed', 'tutup sementara']):\n",
    "                            data[\"Status\"] = \"Tutup Sementara\"\n",
    "                        elif 'closed' in status_text.lower() or 'tutup' in status_text.lower():\n",
    "                            data[\"Status\"] = \"Tutup\"\n",
    "                        else:\n",
    "                            data[\"Status\"] = \"Aktif\"\n",
    "                        break\n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            # Extract Operation Hours\n",
    "            try:\n",
    "                hours_button = driver.find_element(By.CSS_SELECTOR, \"button[data-item-id='oh']\")\n",
    "                hours_aria = hours_button.get_attribute(\"aria-label\")\n",
    "                if hours_aria:\n",
    "                    data[\"Operation Hours\"] = hours_aria\n",
    "                    logging.info(f\"Card {i+1}: ‚úì Hours: {hours_aria[:50]}...\")\n",
    "            except Exception:\n",
    "                try:\n",
    "                    hours_div = driver.find_element(By.XPATH, \"//div[contains(@class, 'ZDu9vd')]//span\")\n",
    "                    hours_text = hours_div.text.strip()\n",
    "                    if hours_text and re.search(r'\\d{1,2}[:.\\-]\\d{2}', hours_text):\n",
    "                        data[\"Operation Hours\"] = hours_text\n",
    "                        logging.info(f\"Card {i+1}: ‚úì Hours: {hours_text}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "            \n",
    "            # Get coordinates\n",
    "            if not lat or not lon:\n",
    "                lat, lon = extract_coords_from_page(driver)\n",
    "            if lat and lon:\n",
    "                data[\"Latitude\"], data[\"Longitude\"] = lat, lon\n",
    "                logging.info(f\"Card {i+1}: ‚úì Koordinat: {lat}, {lon}\")\n",
    "            else:\n",
    "                logging.warning(f\"Card {i+1}: ‚úó Koordinat tidak ditemukan\")\n",
    "                \n",
    "            data[\"Status\"] = get_place_status(driver)\n",
    "            \n",
    "            # Validasi data sebelum menambahkan ke hasil\n",
    "            if data[\"Actual Place Name\"] != \"Gagal\" and not data[\"Actual Place Name\"].startswith(\"Error:\"):\n",
    "                results_data.append(data)\n",
    "                logging.info(f\"‚úì Berhasil scrape card {i+1}: {data['Actual Place Name']}\")\n",
    "            else:\n",
    "                logging.warning(f\"‚úó Gagal scrape card {i+1}: {data['Actual Place Name']}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error di card {i+1} untuk '{place_name}': {str(e)[:100]}\")\n",
    "            continue\n",
    "\n",
    "    # Jika tidak ada hasil yang valid, return error message\n",
    "    if not results_data:\n",
    "        logging.error(f\"Semua card gagal untuk '{place_name}'. Kemungkinan multiple results atau elemen tidak ditemukan.\")\n",
    "        return [{\"Place\": place_name, \"Actual Place Name\": \"Error: Multiple results - gagal semua kartu\", \"Address\": \"Gagal\", \"Phone Number\": \"Gagal\", \"Website\": \"Gagal\", \"Latitude\": \"Gagal\", \"Longitude\": \"Gagal\", \"Status\": \"Error\"}]\n",
    "    \n",
    "    return results_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch_results(results, output_csv, append_mode=False):\n",
    "    \"\"\"\n",
    "    Simpan hasil ke Excel dengan opsi append atau replace.\n",
    "    Jika append_mode=True dan file sudah ada, akan di-append.\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        return\n",
    "    \n",
    "    df_result = pd.DataFrame(results)\n",
    "    \n",
    "    # Clean text\n",
    "    def clean_text(x):\n",
    "        if isinstance(x, str):\n",
    "            return (\n",
    "                x.replace('', '')\n",
    "                .replace('\\n', ' ')\n",
    "                .replace('\\r', ' ')\n",
    "                .strip()\n",
    "            )\n",
    "        return x\n",
    "    \n",
    "    df_result = df_result.map(clean_text)\n",
    "    \n",
    "    # Tentukan kolom utama dan tambahan\n",
    "    kolom_utama = [\n",
    "        'idsbr', 'Query', 'Actual Place Name', 'Category', 'Rating',\n",
    "        'Address', 'Phone Number', 'Website', 'Latitude', 'Longitude',\n",
    "        'Status', 'Open Status', 'Operation Hours'\n",
    "    ]\n",
    "    kolom_utama = [col for col in kolom_utama if col in df_result.columns]\n",
    "    kolom_lain = [c for c in df_result.columns if c not in kolom_utama]\n",
    "    df_result = df_result[kolom_utama + kolom_lain]\n",
    "    \n",
    "    # Jika append mode dan file sudah ada, baca dan append\n",
    "    if append_mode and os.path.exists(output_csv):\n",
    "        try:\n",
    "            df_existing = pd.read_csv(output_csv)\n",
    "            df_result = pd.concat([df_existing, df_result], ignore_index=True)\n",
    "            print(f\"  üìä Append {len(results)} items ke {len(df_existing)} existing rows\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Tidak bisa append: {e}. Save sebagai baru.\")\n",
    "    \n",
    "    df_result.to_csv(output_csv, index=False)\n",
    "    print(f\"  üíæ Saved ke: {output_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_existing_results(output_csv):\n",
    "    \"\"\"Load hasil yang sudah ada untuk resume.\"\"\"\n",
    "    if os.path.exists(output_csv):\n",
    "        try:\n",
    "            df = pd.read_csv(output_csv)\n",
    "            existing_ids = set(df['idsbr'].astype(str).values)\n",
    "            print(f\"üìÇ Ditemukan {len(existing_ids)} hasil sebelumnya. Akan skip yang sudah ada.\")\n",
    "            return existing_ids\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Tidak bisa load existing: {e}\")\n",
    "    return set()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_query(args):\n",
    "    \"\"\"\n",
    "    Worker function untuk parallel processing.\n",
    "    Setiap worker membuat driver sendiri, scrape satu query, lalu tutup driver.\n",
    "    \"\"\"\n",
    "    idsbr, query, worker_id = args\n",
    "    driver = None\n",
    "    results_list = []\n",
    "    \n",
    "    try:\n",
    "        driver = init_driver(headless=True, timeout=25)\n",
    "        print(f\"  [Worker {worker_id}] üîç {idsbr} | {query}\")\n",
    "        \n",
    "        result = get_place_info(driver, query, max_result=5, timeout=25)\n",
    "        \n",
    "        if isinstance(result, list):\n",
    "            for r in result:\n",
    "                r['idsbr'] = idsbr\n",
    "                r['Query'] = query\n",
    "                # Cek apakah ada error\n",
    "                if r.get('Actual Place Name', '').startswith('Error:') or r.get('Actual Place Name') == 'Gagal':\n",
    "                    r['Status'] = 'Error'\n",
    "                    print(f\"  [Worker {worker_id}] ‚ö†Ô∏è  Gagal: {r['Actual Place Name']}\")\n",
    "                else:\n",
    "                    if 'Status' not in r or not r['Status']:\n",
    "                        r['Status'] = 'Aktif'\n",
    "                    print(f\"  [Worker {worker_id}] ‚úÖ Berhasil: {r.get('Actual Place Name', 'N/A')}\")\n",
    "                results_list.append(r)\n",
    "        else:\n",
    "            result['idsbr'] = idsbr\n",
    "            result['Query'] = query\n",
    "            # Cek apakah ada error\n",
    "            if result.get('Actual Place Name', '').startswith('Error:') or result.get('Actual Place Name') == 'Gagal':\n",
    "                result['Status'] = 'Error'\n",
    "                print(f\"  [Worker {worker_id}] ‚ö†Ô∏è  Gagal: {result['Actual Place Name']}\")\n",
    "            else:\n",
    "                if 'Status' not in result or not result['Status']:\n",
    "                    result['Status'] = 'Aktif'\n",
    "                print(f\"  [Worker {worker_id}] ‚úÖ Berhasil: {result.get('Actual Place Name', 'N/A')}\")\n",
    "            results_list.append(result)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  [Worker {worker_id}] ‚ùå Error: {str(e)[:100]}\")\n",
    "        results_list.append({\n",
    "            'idsbr': idsbr,\n",
    "            'Query': query,\n",
    "            'Actual Place Name': 'Gagal',\n",
    "            'Status': 'Error'\n",
    "        })\n",
    "    finally:\n",
    "        if driver:\n",
    "            try:\n",
    "                driver.quit()\n",
    "            except Exception:\n",
    "                pass\n",
    "    \n",
    "    return results_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_csv_idsbr_ke_csv(\n",
    "    input_csv=\"./carimap.csv\",\n",
    "    output_csv=\"./carimap2.csv\",\n",
    "    max_workers=5  # Jumlah browser parallel\n",
    "):\n",
    "    \n",
    "    # Mulai timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"Membaca file: {input_csv}\")\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        input_csv,\n",
    "        header=None,\n",
    "        encoding=\"ISO-8859-1\",\n",
    "        usecols=[0, 1],\n",
    "        engine=\"python\"\n",
    "    )\n",
    "    df.columns = ['idsbr', 'query']\n",
    "    df['idsbr'] = (\n",
    "        df['idsbr']\n",
    "        .astype(str)\n",
    "        .str.replace('√Ø¬ª¬ø', '', regex=False)\n",
    "        .str.strip()\n",
    "    )\n",
    "    df['query'] = df['query'].astype(str).str.strip()\n",
    "    df = df[df['query'] != '']\n",
    "\n",
    "    print(f\"Total query valid: {len(df)}\")\n",
    "    \n",
    "    # Load existing results untuk resume\n",
    "    existing_ids = load_existing_results(output_csv)\n",
    "    df_to_scrape = df[~df['idsbr'].astype(str).isin(existing_ids)].reset_index(drop=True)\n",
    "    \n",
    "    if len(df_to_scrape) == 0:\n",
    "        print(\"‚úÖ Semua data sudah di-scrape sebelumnya!\")\n",
    "        return\n",
    "\n",
    "    print(f\"‚è≥ Akan scrape {len(df_to_scrape)} query baru dengan {max_workers} workers parallel\")\n",
    "\n",
    "    # ================================\n",
    "    # SCRAPING PARALLEL - ThreadPoolExecutor\n",
    "    # ================================\n",
    "    results = []\n",
    "    completed = 0\n",
    "    total = len(df_to_scrape)\n",
    "    \n",
    "    # Siapkan arguments untuk setiap query\n",
    "    # Format: (idsbr, query, worker_id)\n",
    "    query_args = [\n",
    "        (row['idsbr'], row['query'], idx % max_workers + 1) \n",
    "        for idx, (_, row) in enumerate(df_to_scrape.iterrows())\n",
    "    ]\n",
    "    \n",
    "    # Process menggunakan ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_query = {\n",
    "            executor.submit(process_single_query, args): args \n",
    "            for args in query_args\n",
    "        }\n",
    "        \n",
    "        # Collect results as they complete\n",
    "        for future in as_completed(future_to_query):\n",
    "            args = future_to_query[future]\n",
    "            completed += 1\n",
    "            \n",
    "            try:\n",
    "                result_list = future.result()\n",
    "                results.extend(result_list)\n",
    "                print(f\"\\n[{completed}/{total}] Completed: {args[0]} | {args[1][:50]}...\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n[{completed}/{total}] ‚ùå Future error for {args[0]}: {str(e)[:100]}\")\n",
    "                results.append({\n",
    "                    'idsbr': args[0],\n",
    "                    'Query': args[1],\n",
    "                    'Actual Place Name': 'Gagal',\n",
    "                    'Status': 'Error'\n",
    "                })\n",
    "            \n",
    "            # Save batch setiap 50 item\n",
    "            if completed % 50 == 0:\n",
    "                print(f\"\\nüìã Saving batch at {completed}/{total}...\")\n",
    "                save_batch_results(results, output_csv, append_mode=(completed > 50))\n",
    "                results = []\n",
    "            \n",
    "            # Small delay untuk menghindari rate limiting\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    # Save hasil akhir jika ada sisa\n",
    "    if results:\n",
    "        print(f\"\\nüìã Saving final batch ({len(results)} items)...\")\n",
    "        save_batch_results(results, output_csv, append_mode=True)\n",
    "\n",
    "    # Hitung durasi eksekusi\n",
    "    end_time = time.time()\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    hours = int(elapsed_seconds // 3600)\n",
    "    minutes = int((elapsed_seconds % 3600) // 60)\n",
    "    seconds = int(elapsed_seconds % 60)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"‚úÖ SCRAPING SELESAI\")\n",
    "    print(f\"üìÅ File tersimpan di: {output_csv}\")\n",
    "    print(f\"üìä Total query di-scrape: {total}\")\n",
    "    print(f\"‚è±Ô∏è  Waktu eksekusi: {hours} jam {minutes} menit {seconds} detik\")\n",
    "    if total > 0:\n",
    "        avg_per_query = elapsed_seconds / total\n",
    "        print(f\"üìà Rata-rata per query: {avg_per_query:.2f} detik\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Membersihkan dan normalisasi teks untuk perbandingan\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    # Hapus karakter khusus tapi pertahankan spasi\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # Hapus spasi berlebih\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(query, place_name, address):\n",
    "    \"\"\"Menghitung similarity score antara query dengan place_name + address\"\"\"\n",
    "    query_clean = clean_text(query)\n",
    "    place_clean = clean_text(place_name)\n",
    "    address_clean = clean_text(address)\n",
    "    \n",
    "    # Gabungkan place name dan address\n",
    "    combined = f\"{place_clean} {address_clean}\"\n",
    "    \n",
    "    # Hitung similarity menggunakan SequenceMatcher\n",
    "    similarity = SequenceMatcher(None, query_clean, combined).ratio()\n",
    "    \n",
    "    # Berikan bonus jika place_name sangat mirip dengan query\n",
    "    place_similarity = SequenceMatcher(None, query_clean, place_clean).ratio()\n",
    "    \n",
    "    # Weighted score: 60% dari combined similarity, 40% dari place similarity\n",
    "    final_score = (similarity * 0.6) + (place_similarity * 0.4)\n",
    "    \n",
    "    return final_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(input_file, output_file):\n",
    "    \"\"\"Memproses CSV dan melakukan deduplikasi berdasarkan kecocokan query\"\"\"\n",
    "    \n",
    "    print(f\"Membaca file: {input_file}\")\n",
    "    # df = pd.read_csv(input_file)\n",
    "    df = pd.read_excel(input_file)\n",
    "\n",
    "    # print(df)\n",
    "    \n",
    "    # Pastikan kolom yang diperlukan ada\n",
    "    required_cols = ['idsbr', 'Query', 'Actual Place Name', 'Address']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Error: Kolom yang hilang: {missing_cols}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Total baris: {len(df)}\")\n",
    "    \n",
    "    # Tambahkan kolom untuk similarity score dan validasi\n",
    "    df['similarity_score'] = 0.0\n",
    "    df['Validasi'] = 'Tidak Ditemukan'\n",
    "    \n",
    "    # Hitung similarity score untuk setiap baris\n",
    "    for idx, row in df.iterrows():\n",
    "        score = calculate_similarity(\n",
    "            row['Query'],\n",
    "            row['Actual Place Name'],\n",
    "            row['Address']\n",
    "        )\n",
    "        df.at[idx, 'similarity_score'] = score\n",
    "\n",
    "    # print(df)\n",
    "    \n",
    "    # Group by idsbr untuk mencari winner\n",
    "    grouped = df.groupby('idsbr')\n",
    "    \n",
    "    processed_rows = []\n",
    "    \n",
    "    for idsbr, group in grouped:\n",
    "        if pd.isna(idsbr) or str(idsbr).strip() == '':\n",
    "            # Jika idsbr kosong, tandai sebagai tidak ditemukan\n",
    "            for idx, row in group.iterrows():\n",
    "                row_dict = row.to_dict()\n",
    "                row_dict['Validasi'] = 'Tidak Ditemukan'\n",
    "\n",
    "                processed_rows.append(row_dict)\n",
    "            continue\n",
    "        \n",
    "        # Urutkan berdasarkan similarity score (descending)\n",
    "        sorted_group = group.sort_values('similarity_score', ascending=False)\n",
    "        \n",
    "        # Ambil winner (score tertinggi)\n",
    "        winner_idx = sorted_group.index[0]\n",
    "        \n",
    "        for idx, row in sorted_group.iterrows():\n",
    "            row_dict = row.to_dict()\n",
    "            \n",
    "            if idx == winner_idx:\n",
    "                # Ini adalah winner\n",
    "                row_dict['Validasi'] = 'Ditemukan'\n",
    "                row_dict['idsbr'] = idsbr\n",
    "            else:\n",
    "                # Ini adalah loser, kosongkan idsbr\n",
    "                row_dict['Validasi'] = 'Tidak Ditemukan'\n",
    "            \n",
    "            processed_rows.append(row_dict)\n",
    "\n",
    "\n",
    "    # Buat dataframe baru dari hasil\n",
    "    result_df = pd.DataFrame(processed_rows)\n",
    "    print(result_df)\n",
    "    \n",
    "    # Hapus kolom similarity_score (kolom temporary)\n",
    "    result_df = result_df.drop('similarity_score', axis=1)\n",
    "    \n",
    "    # Urutkan ulang kolom agar Validasi di akhir\n",
    "    cols = [col for col in result_df.columns if col != 'Validasi']\n",
    "    cols.append('Validasi')\n",
    "    result_df = result_df[cols]\n",
    "    \n",
    "    # Simpan ke file output\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Tampilkan statistik\n",
    "    print(f\"\\n=== STATISTIK ===\")\n",
    "    print(f\"Total baris input: {len(df)}\")\n",
    "    print(f\"Total baris output: {len(result_df)}\")\n",
    "    print(f\"Jumlah 'Ditemukan': {len(result_df[result_df['Validasi'] == 'Ditemukan'])}\")\n",
    "    print(f\"Jumlah 'Tidak Ditemukan': {len(result_df[result_df['Validasi'] == 'Tidak Ditemukan'])}\")\n",
    "    print(f\"\\nHasil disimpan ke: {output_file}\")\n",
    "    \n",
    "    return result_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membaca file: ./carimap.csv\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Defining usecols with out-of-bounds indices is not allowed. [1] are out-of-bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Contoh penggunaan\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m#Scraping\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mscraping_csv_idsbr_ke_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# input_file = \"./carimap2.csv\"  # Ganti dengan nama file input Anda\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# output_file = \"output_carimap.csv\"  # Nama file output\u001b[39;00m\n\u001b[32m      9\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m#     import traceback\u001b[39;00m\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m#     traceback.print_exc()\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mscraping_csv_idsbr_ke_csv\u001b[39m\u001b[34m(input_csv, output_csv, max_workers)\u001b[39m\n\u001b[32m      8\u001b[39m start_time = time.time()\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMembaca file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_csv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mISO-8859-1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpython\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m df.columns = [\u001b[33m'\u001b[39m\u001b[33midsbr\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     20\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33midsbr\u001b[39m\u001b[33m'\u001b[39m] = (\n\u001b[32m     21\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33midsbr\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     22\u001b[39m     .astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m     23\u001b[39m     .str.replace(\u001b[33m'\u001b[39m\u001b[33m√Ø¬ª¬ø\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, regex=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     24\u001b[39m     .str.strip()\n\u001b[32m     25\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:133\u001b[39m, in \u001b[36mPythonParser.__init__\u001b[39m\u001b[34m(self, f, **kwds)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28mself\u001b[39m._col_indices: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    128\u001b[39m columns: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar | \u001b[38;5;28;01mNone\u001b[39;00m]]\n\u001b[32m    129\u001b[39m (\n\u001b[32m    130\u001b[39m     columns,\n\u001b[32m    131\u001b[39m     \u001b[38;5;28mself\u001b[39m.num_original_columns,\n\u001b[32m    132\u001b[39m     \u001b[38;5;28mself\u001b[39m.unnamed_cols,\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_infer_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Now self.columns has the set of columns that we will process.\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# The original set is stored in self.original_columns.\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'index_names'\u001b[39;00m\n\u001b[32m    138\u001b[39m (\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mself\u001b[39m.columns,\n\u001b[32m    140\u001b[39m     \u001b[38;5;28mself\u001b[39m.index_names,\n\u001b[32m   (...)\u001b[39m\u001b[32m    145\u001b[39m     \u001b[38;5;28mself\u001b[39m.index_names,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    146\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:551\u001b[39m, in \u001b[36mPythonParser._infer_columns\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    549\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m names:\n\u001b[32m    550\u001b[39m     columns = [\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(ncols))]\n\u001b[32m--> \u001b[39m\u001b[32m551\u001b[39m     columns = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_usecols\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.usecols \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(names) >= ncols:\n\u001b[32m    553\u001b[39m     columns = \u001b[38;5;28mself\u001b[39m._handle_usecols([names], names, ncols)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:617\u001b[39m, in \u001b[36mPythonParser._handle_usecols\u001b[39m\u001b[34m(self, columns, usecols_key, num_original_columns)\u001b[39m\n\u001b[32m    613\u001b[39m     missing_usecols = [\n\u001b[32m    614\u001b[39m         col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.usecols \u001b[38;5;28;01mif\u001b[39;00m col >= num_original_columns\n\u001b[32m    615\u001b[39m     ]\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m missing_usecols:\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ParserError(\n\u001b[32m    618\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mDefining usecols with out-of-bounds indices is not allowed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    619\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_usecols\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m are out-of-bounds.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    620\u001b[39m         )\n\u001b[32m    621\u001b[39m     col_indices = \u001b[38;5;28mself\u001b[39m.usecols\n\u001b[32m    623\u001b[39m columns = [\n\u001b[32m    624\u001b[39m     [n \u001b[38;5;28;01mfor\u001b[39;00m i, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(column) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m col_indices]\n\u001b[32m    625\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns\n\u001b[32m    626\u001b[39m ]\n",
      "\u001b[31mParserError\u001b[39m: Defining usecols with out-of-bounds indices is not allowed. [1] are out-of-bounds."
     ]
    }
   ],
   "source": [
    "# Contoh penggunaan\n",
    "if __name__ == \"__main__\":\n",
    "    #Scraping\n",
    "    scraping_csv_idsbr_ke_csv()\n",
    "\n",
    "    \n",
    "    # input_file = \"./carimap2.csv\"  # Ganti dengan nama file input Anda\n",
    "    # output_file = \"output_carimap.csv\"  # Nama file output\n",
    "    \n",
    "    # try:\n",
    "    #     result = process_csv(input_file, output_file)\n",
    "    #     print(\"\\nProses selesai!\")\n",
    "        \n",
    "    #     # Tampilkan preview hasil (5 baris pertama)\n",
    "    #     print(\"\\n=== PREVIEW HASIL (5 baris pertama) ===\")\n",
    "    #     print(result[['idsbr', 'Query', 'Actual Place Name', 'Validasi']].head())\n",
    "    #     # print(result)\n",
    "        \n",
    "    # except FileNotFoundError:\n",
    "    #     print(f\"Error: File '{input_file}' tidak ditemukan!\")\n",
    "    #     print(\"Pastikan file CSV ada di direktori yang sama dengan script ini.\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error: {e}\")\n",
    "    #     import traceback\n",
    "    #     traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
